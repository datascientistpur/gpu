{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from cuml.preprocessing import model_selection\n",
    "from itertools import chain\n",
    "from scipy.stats import chi2_contingency\n",
    "import cuml\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padas version 0.25.3\n",
      "numpy version 1.18.1\n",
      "cudf version 0.13.0+0.ga2804c3.dirty\n",
      "cuml version 0.13.0+0.g7544c43.dirty\n",
      "cuda version 9.0.176\n"
     ]
    }
   ],
   "source": [
    "print(\"padas version\",pd.__version__)\n",
    "print(\"numpy version\",np.__version__)\n",
    "print(\"cudf version\",cudf.__version__)\n",
    "print(\"cuml version\",cuml.__version__)\n",
    "print(\"cuda version\",torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Function declarations'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Function declarations'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Append Frames'''\n",
    "def append_frames(data1,data2):\n",
    "    append_data=cudf.DataFrame()\n",
    "    if(len(data1)>0):\n",
    "        if(len(data2)>0):\n",
    "            append_data=cudf.concat([data1,data2],ignore_index=True,axis=0)\n",
    "        else:\n",
    "            append_data=data1\n",
    "    else:\n",
    "        append_data=data2\n",
    "    return(append_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_sorting(data):\n",
    "    data['temp']=data.cuts\n",
    "    data['temp']=data.temp.str.replace(\"%\",\"\")\n",
    "    data['temp']=data.temp.str.split(\"-\")[0]\n",
    "    data['temp']=data.temp.astype(\"int32\")\n",
    "    data=data.sort_values(['var_name','temp'],ascending=True)\n",
    "    data=data.drop(columns=[\"temp\"])\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Univariate cuts for numeral type.\n",
    "Since there is not qcut functioanlity in CuDF,this function is a work-around for qcut[only for numeric type]'''\n",
    "def univariate_cuts_mapper_numeric(data,var):\n",
    "    stats_frame=cudf.DataFrame()\n",
    "    for i in range(0,len(var)):\n",
    "        \n",
    "        tmp=data[var[i]].describe(percentiles=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "        stats_frame1=cudf.DataFrame()\n",
    "        stats_frame1['cut_val']=tmp.copy()\n",
    "        stats_frame1['desc']=stats_frame1.index\n",
    "        stats_frame1=stats_frame1[stats_frame1.desc.str.contains(\"%\")]\n",
    "        decile_var=var[i]+'__decile_cuts'\n",
    "        data[decile_var]='-1'\n",
    "        stats_frame1['var_name']=var[i]\n",
    "        processed_data=cudf.DataFrame()\n",
    "        k=''\n",
    "        for j in stats_frame1.desc:\n",
    "            temp_data=data[data[var[i]]<=stats_frame1.cut_val[stats_frame1.desc==j][0]]\n",
    "            if(len(temp_data)>0):\n",
    "                temp_data[decile_var]=j\n",
    "                k=j\n",
    "                processed_data=append_frames(processed_data,temp_data)\n",
    "                data=data[~data.ID.isin(temp_data.ID)]\n",
    "            else:\n",
    "                processed_data.loc[processed_data[decile_var].str.contains(k),decile_var]=k+\"-\"+j\n",
    "                stats_frame1.loc[stats_frame1.desc==k,'desc']=k+\"-\"+j\n",
    "                stats_frame1=stats_frame1[stats_frame1.desc!=j]\n",
    "            \n",
    "        stats_frame=append_frames(stats_frame,stats_frame1)\n",
    "        data=processed_data\n",
    "        data.loc[data[decile_var]=='-1',decile_var]=\"Null\"\n",
    "    return([data,stats_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Univariate for character type'''\n",
    "def univariate_cuts_mapper_char(data,var):\n",
    "    for i in var:\n",
    "        cut_var=i+\"__cuts\"\n",
    "        data[cut_var]=data[i]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_univariates(data):\n",
    "    vars=data.columns[data.columns.str.contains('_cuts$')]\n",
    "    summarised_frame=cudf.DataFrame()\n",
    "    for i in vars:\n",
    "        tmp_frame=cudf.DataFrame()\n",
    "        tmp_frame['cases']=data.groupby(i)['target'].count()\n",
    "        tmp_frame['popn']=tmp_frame['cases']/sum(tmp_frame['cases'])\n",
    "        tmp_frame['cuts']=tmp_frame.index\n",
    "        tmp_frame['var_name']=i.split(\"__\")[0]\n",
    "        if(i.split(\"__\")[1]=='decile_cuts'):\n",
    "            tmp_frame['var_type']=\"numeric\"\n",
    "        else:\n",
    "            tmp_frame['var_type']=\"character\"\n",
    "        summarised_frame=append_frames(summarised_frame,tmp_frame)\n",
    "        summarised_frame.index=summarised_frame.var_name+\"_\"+summarised_frame.cuts\n",
    "        summarised_frame=tabular_sorting(summarised_frame)\n",
    "    return(summarised_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_bivariates(data):\n",
    "    vars=data.columns[data.columns.str.contains('_cuts$')]\n",
    "    summarised_frame=cudf.DataFrame()\n",
    "    for i in vars:\n",
    "        #print(i)\n",
    "        tmp_frame=data.groupby(i,as_index=False).agg({'target':['count','sum']})\n",
    "        tmp_frame.columns=['cuts',\"cases\",\"target\"]\n",
    "        tmp_frame['non_target']=tmp_frame.cases-tmp_frame.target\n",
    "        tmp_frame['popn']=tmp_frame.cases/sum(tmp_frame.cases)\n",
    "        tmp_frame['non_target_distbn']=tmp_frame.non_target/sum(tmp_frame.non_target)\n",
    "        tmp_frame['target_distbn']=tmp_frame.target/sum(tmp_frame.target)\n",
    "        tmp_frame['target_rate']=tmp_frame['target']/tmp_frame['cases']\n",
    "        tmp_frame['WOE']=np.log((tmp_frame.non_target_distbn/tmp_frame.target_distbn))\n",
    "        tmp_frame['IV']=(tmp_frame.non_target_distbn-tmp_frame.target_distbn)*tmp_frame.WOE\n",
    "        tmp_frame['var_name']=i.split(\"__\")[0]\n",
    "        \n",
    "        summarised_frame=append_frames(summarised_frame,tmp_frame)\n",
    "    summarised_frame=tabular_sorting(summarised_frame)\n",
    "    #summarised_frame.index=summarised_frame.var+\"_\"+summarised_frame.cuts\n",
    "    return(summarised_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########Cramer's V\n",
    "def cramers_V(var1,var2) :\n",
    "  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) # Cross table building\n",
    "  stat = chi2_contingency(crosstab)[0] # Keeping of the test statistic of the Chi2 test\n",
    "  obs = np.sum(crosstab) # Number of observations\n",
    "  mini = min(crosstab.shape)-1 # Take the minimum value between the columns and the rows of the cross table\n",
    "  return (stat/(obs*mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shravan/anaconda3/lib/python3.7/site-packages/fsspec/implementations/local.py:33: FutureWarning: The default value of auto_mkdir=True has been deprecated and will be changed to auto_mkdir=False by default in a future release.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Loading the sample UCI Credit Card default dataset\n",
    "Dataset Description:\n",
    "LIMIT_BAL: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "Sex: Gender (1 = male; 2 = female).\n",
    "Education: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "MARRIAGE: Marital status (1 = married; 2 = single; 3 = others).\n",
    "Age: Age (year).\n",
    "PAY_0-PAY_6: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "BILL_AMT1-BILL_AMT6:statement (NT dollar).1= amount of bill statement in September, 2005; 2= amount of bill statement in August, 2005; . . .; 6 = amount of bill statement in April, 2005.\n",
    "PAY_AMT1-PAY_AMT6: Amount of previous payment (NT dollar). 1= amount paid in September, 2005; 2 = amount paid in August, 2005; . . .;6 = amount paid in April, 2005.\n",
    "'''\n",
    "file=cudf.read_csv(\"uci_default of credit card clients.csv\",delimiter=\",\")\n",
    "file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Random split for train/test\n",
    "train_test_split takes the following parameters:\n",
    "1. CuDF\n",
    "2. y i.e. target\n",
    "3. random_seed either a seed generator numeral or randomseed object\n",
    "4. train population\n",
    "'''\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(file,\"default\",random_state=300,train_size=0.75)\n",
    "train=x_train\n",
    "train['target']=y_train\n",
    "test=x_test\n",
    "test['target']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Feature name generator i.e. input for univariates and bivariates'''\n",
    "pattern_cols = []\n",
    "_ = [pattern_cols.extend(item) if isinstance(item, list) else pattern_cols.append(item) for item in train.columns[train.columns.str.contains(\"PAY_\\\\d+$\")].values.tolist() if item]\n",
    "char_names=['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "char_names.extend(pattern_cols)\n",
    "target_name=['target']\n",
    "excluded_name=['ID']\n",
    "numeric_names=train.columns[~train.columns.isin(chain(char_names,target_name,excluded_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting character type for char columns'''\n",
    "for i in char_names:\n",
    "    train[i]=train[i].astype(\"str\")\n",
    "    test[i]=test[i].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Computing Univariates'''\n",
    "[train1,cuts_numeric]=univariate_cuts_mapper_numeric(train,numeric_names)\n",
    "train1=univariate_cuts_mapper_char(train1,char_names)\n",
    "univariates=tabulate_univariates(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Computing Bivariates'''\n",
    "bivariates=tabulate_bivariates(train1)\n",
    "var_iv=bivariates.groupby('var_name')['IV'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''Computing Cramer's V '''\n",
    "cramers_table=pd.DataFrame()\n",
    "train_file11=train1.to_pandas()\n",
    "\n",
    "for i in np.arange(0,len(var_iv.index)):\n",
    "    for j in np.arange(i+1,len(var_iv.index)):\n",
    "        frame=pd.DataFrame({'var1':[var_iv.index[i]],'var2':[var_iv.index[j]],'cramers':[cramers_V(train_file11.iloc[1:len(train1),i],train_file11.iloc[1:len(train1),j])]})\n",
    "        cramers_table=cramers_table.append(frame,ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
